import kss
import httpx
import json
from typing import List, Dict, Set, Tuple
from utils.hybrid_utils import normalize_symptom_id, is_known_symptom

LLM_PROMPT_TEMPLATE = """You are a medical AI that specializes in extracting symptoms from user input.

Your task is to extract ONLY the medical symptoms explicitly mentioned in the following Korean sentence.
- DO NOT guess symptoms that are not clearly stated.
- DO NOT infer, translate, or explain.
- DO NOT include Korean.
- DO NOT add modifiers like (mild), (severe), etc.
- DO NOT include adjectives like "persistent", "chronic", or "frequent" in the symptom field. Instead, express them using the "time" field as "persistent".
Respond ONLY with a valid JSON array of objects.
Each object must include:
- "symptom": an English medical keyword (e.g., "fever", "cough", "abdominal pain")
- "time": "morning", "afternoon", "evening", "night", "persistent", or null

Valid Output:
[
  { "symptom": "fever", "time": "night" },
  { "symptom": "headache", "time": null },
  { "symptom": "cough", "time": "persistent" }
]

Now extract symptoms from this sentence:
"{sentence}"
"""

OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "mistral"


# âœ… ë¯¸ì •ì˜ ì¦ìƒ ë¡œê·¸ (ì „ì—­ ì €ìž¥ì†Œ)
unknown_symptom_log: Dict[str, Set[str]] = {}

def split_korean_sentences(text: str) -> List[str]:
    return kss.split_sentences(text)


async def extract_single_sentence_with_llm(sentence: str) -> List[Dict[str, str]]:
    prompt = LLM_PROMPT_TEMPLATE.replace("{sentence}", sentence.strip())

    async with httpx.AsyncClient() as client:
        try:
            response = await client.post(
                OLLAMA_URL,
                json={
                    "model": MODEL_NAME,
                    "prompt": prompt,
                    "stream": False
                },
                timeout=30.0
            )
            response.raise_for_status()
            raw = response.text.strip()
            print(f"ðŸ“© LLM ì‘ë‹µ ì›ë¬¸:\n{raw}")

            output = response.json().get("response", "").strip()
            parsed = json.loads(output) if output.startswith("[") else []

            # âœ… ë¯¸ì •ì˜ ì¦ìƒ ê¸°ë¡
            for item in parsed:
                symptom = item.get("symptom")
                norm = normalize_symptom_id(symptom)
                if not is_known_symptom(norm):
                    if norm not in unknown_symptom_log:
                        unknown_symptom_log[norm] = set()
                    unknown_symptom_log[norm].add(sentence.strip())

            return parsed

        except Exception as e:
            print(f"âš ï¸ LLM JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return []


async def extract_symptoms_with_llm(text: str) -> List[Dict[str, str]]:
    sentences = split_korean_sentences(text)
    all_results: List[Dict[str, str]] = []
    seen = set()

    print("\n" + "=" * 60)
    print(f"ðŸ§¾ ìž…ë ¥ ë¬¸ìž¥: {text}")
    print(f"âœ‚ï¸ ë¶„ë¦¬ëœ ë¬¸ìž¥ ìˆ˜: {len(sentences)}")

    async with httpx.AsyncClient() as client:
        for idx, sentence in enumerate(sentences, 1):
            prompt = LLM_PROMPT_TEMPLATE.replace("{sentence}", sentence.strip())
            print(f"\nðŸ§  [ë¬¸ìž¥ {idx}] '{sentence.strip()}'")

            try:
                response = await client.post(
                    OLLAMA_URL,
                    json={
                        "model": MODEL_NAME,
                        "prompt": prompt,
                        "stream": False
                    },
                    timeout=30.0
                )
                response.raise_for_status()

                raw = response.text.strip()
                print(f"ðŸ“© LLM ì‘ë‹µ ì›ë¬¸:\n{raw}")

                output = response.json().get("response", "").strip()
                parsed = json.loads(output) if output.startswith("[") else []

                # âœ… ë¯¸ì •ì˜ ì¦ìƒ ê¸°ë¡
                for item in parsed:
                    symptom = item.get("symptom")
                    norm = normalize_symptom_id(symptom)
                    if not is_known_symptom(norm):
                        if norm not in unknown_symptom_log:
                            unknown_symptom_log[norm] = set()
                        unknown_symptom_log[norm].add(sentence.strip())

                    key = (symptom, item.get("time"))
                    if key not in seen:
                        seen.add(key)
                        all_results.append(item)

            except Exception as e:
                print(f"âŒ LLM ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    print("\n" + "-" * 60)
    print("ðŸ©º ìµœì¢… í†µí•© ì¦ìƒ ì¶”ì¶œ ê²°ê³¼:")
    for result in all_results:
        print(f"   - {result['symptom']} (time: {result['time']})")
    print("=" * 60)

    return all_results


# âœ… ìƒˆë¡œìš´ ë¯¸ì •ì˜ ì¦ìƒ ë¡œê·¸ ì¡°íšŒìš© í•¨ìˆ˜ (ì™¸ë¶€ ëª¨ë“ˆì—ì„œ ì ‘ê·¼ ê°€ëŠ¥)
def get_unknown_symptom_log() -> Dict[str, List[str]]:
    return {k: list(v) for k, v in unknown_symptom_log.items()}